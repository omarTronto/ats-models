{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38de714d-81e4-47ba-9394-0fffe31cce56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 1. Prepare the pretrained models `trimmed_longmbart` and `trimmed_mbart`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e5f107d-6f95-405e-952c-9ed94374aee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scripts import prepare_trimmed_mbart_model, prepare_trimmed_longmbart_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2b9d4c3-b7f3-48ef-b767-e3038c110a18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:loading pretrained models and config...\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.19k/1.19k [00:00<00:00, 367kB/s]\n",
      "Downloading (…)\"pytorch_model.bin\";: 100%|██████████| 2.44G/2.44G [00:24<00:00, 98.5MB/s]\n",
      "Downloading (…)neration_config.json: 100%|██████████| 205/205 [00:00<00:00, 66.7kB/s]\n",
      "Downloading (…)tencepiece.bpe.model: 100%|██████████| 5.07M/5.07M [00:06<00:00, 833kB/s]\n",
      "100%|██████████| 215177/215177 [03:26<00:00, 1041.87it/s] \n",
      "INFO:__main__:saving reduced tokenizer vocabulary with size 34850\n",
      "INFO:__main__:saving model to pretrained_models/trimmed_mbart_35k\n",
      "INFO:__main__:saving tokenizer\n"
     ]
    }
   ],
   "source": [
    "prepare_trimmed_mbart_model(trimmed_vocab_size_in_k='35')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311c8350-9ca9-4d16-9a77-5397e1c4dc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:loading pretrained models and config...\n",
      "100%|██████████| 215177/215177 [03:25<00:00, 1045.29it/s] \n",
      "INFO:__main__:saving reduced tokenizer vocabulary with size 34850\n",
      "INFO:__main__:saving model to pretrained_models/trimmed_longmbart_35k\n",
      "INFO:__main__:saving tokenizer\n"
     ]
    }
   ],
   "source": [
    "prepare_trimmed_longmbart_model(trimmed_vocab_size_in_k='35', max_pos=2048, attention_window=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dbf411-2e3d-4dd6-b3dd-8de5c3f92223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7398639a-939e-415c-9566-033cd1e7f8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2bb24c-357d-4fb5-9f96-6103ea17b806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fe6fcd8-e7df-4139-b063-b3d9b8c97c5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 2. Finetune the pretrained models `trimmed_longmbart` and `trimmed_mbart` stored @ `pretrained_models`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c24a0d-f28e-46b2-85d6-e1c0b5f0a90c",
   "metadata": {},
   "source": [
    "**Please run the bash script `pipeline_finetune.sh` in terminal to run the finetuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9821b0-30ee-4c47-b377-61a5a28351a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde8df4f-e3ae-42fa-a318-7414ebe8c425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5018902-54fa-4bdd-a385-5b30de985486",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 3. Evaluate src2scr baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e1ed3a7-9408-478a-b42c-6fe0e415b112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scripts import evaluate_baseline_src2src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d159b468-b86b-44b2-ac6b-14a21c3ab9f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add your test set path to the lists\n",
    "# test set path should point to a directory that contains a `test.src` and `test.tgt` files\n",
    "\n",
    "\n",
    "docs_test_sets = [\n",
    "    'datasets/prepared_datasets/docs/DEplain-APA',\n",
    "    'datasets/prepared_datasets/docs/DEplain-web',\n",
    "    'datasets/prepared_datasets/docs/20Min',\n",
    "]\n",
    "\n",
    "sents_test_sets = [\n",
    "    'datasets/prepared_datasets/sents/DEplain-APA',\n",
    "    'datasets/prepared_datasets/sents/DEplain-web',\n",
    "    'datasets/prepared_datasets/sents/APA_LHA_A2',\n",
    "    'datasets/prepared_datasets/sents/APA_LHA_B1',\n",
    "    'datasets/prepared_datasets/sents/TCDE19',\n",
    "    'datasets/prepared_datasets/sents/Geolingo'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86b54743-3a2c-4aac-8fb2-7180f71ee3f4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating document level test sets...\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating src2src model on DEplain-APA.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating src2src on DEplain-APA successfully.\n",
      "Evaluation metrics: {'bleu': 34.247, 'sari': 17.637, 'bertscore_precision': 0.583, 'bertscore_recall': 0.605, 'bertscore_f1': 0.595, 'sent_FRE': 61.411, 'corpus_FRE': 58.85, 'model': 'src2src', 'test_set': 'DEplain-APA', 'level': 'document'}\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating src2src model on DEplain-web.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating src2src on DEplain-web successfully.\n",
      "Evaluation metrics: {'bleu': 23.132, 'sari': 12.848, 'bertscore_precision': 0.432, 'bertscore_recall': 0.569, 'bertscore_f1': 0.498, 'sent_FRE': 56.877, 'corpus_FRE': 59.4, 'model': 'src2src', 'test_set': 'DEplain-web', 'level': 'document'}\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating src2src model on 20Min.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating src2src on 20Min successfully.\n",
      "Evaluation metrics: {'bleu': 2.051, 'sari': 1.953, 'bertscore_precision': 0.029, 'bertscore_recall': 0.359, 'bertscore_f1': 0.179, 'sent_FRE': 54.665, 'corpus_FRE': 54.45, 'model': 'src2src', 'test_set': '20Min', 'level': 'document'}\n",
      "==================================================\n",
      "==================================================\n",
      "==================================================\n",
      "==================================================\n",
      "Evaluating sentence level sets...\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating src2src model on DEplain-APA.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating src2src model on datasets/prepared_datasets/sents/DEplain-APA successfully.\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating src2src model on DEplain-web.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating src2src model on datasets/prepared_datasets/sents/DEplain-web successfully.\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating src2src model on APA_LHA_A2.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating src2src model on datasets/prepared_datasets/sents/APA_LHA_A2 successfully.\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating src2src model on APA_LHA_B1.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating src2src model on datasets/prepared_datasets/sents/APA_LHA_B1 successfully.\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating src2src model on TCDE19.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating src2src model on datasets/prepared_datasets/sents/TCDE19 successfully.\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating src2src model on Geolingo.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating src2src model on datasets/prepared_datasets/sents/Geolingo successfully.\n",
      "==================================================\n",
      "==================================================\n",
      "==================================================\n",
      "==================================================\n",
      "==================================================\n",
      "==================================================\n",
      "Saving evaluation metrics to csv file...\n",
      "==================================================\n",
      "==================================================\n",
      "==================================================\n",
      "==================================================\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test_set</th>\n",
       "      <th>level</th>\n",
       "      <th>bleu</th>\n",
       "      <th>sari</th>\n",
       "      <th>bertscore_precision</th>\n",
       "      <th>bertscore_recall</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>sent_FRE</th>\n",
       "      <th>corpus_FRE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>src2src</td>\n",
       "      <td>DEplain-APA</td>\n",
       "      <td>document</td>\n",
       "      <td>34.247</td>\n",
       "      <td>17.637</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.595</td>\n",
       "      <td>61.411</td>\n",
       "      <td>58.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>src2src</td>\n",
       "      <td>DEplain-web</td>\n",
       "      <td>document</td>\n",
       "      <td>23.132</td>\n",
       "      <td>12.848</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.498</td>\n",
       "      <td>56.877</td>\n",
       "      <td>59.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>src2src</td>\n",
       "      <td>20Min</td>\n",
       "      <td>document</td>\n",
       "      <td>2.051</td>\n",
       "      <td>1.953</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.179</td>\n",
       "      <td>54.665</td>\n",
       "      <td>54.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>src2src</td>\n",
       "      <td>DEplain-APA</td>\n",
       "      <td>sentence</td>\n",
       "      <td>26.893</td>\n",
       "      <td>15.249</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.633</td>\n",
       "      <td>59.230</td>\n",
       "      <td>58.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>src2src</td>\n",
       "      <td>DEplain-web</td>\n",
       "      <td>sentence</td>\n",
       "      <td>20.854</td>\n",
       "      <td>11.931</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.455</td>\n",
       "      <td>60.825</td>\n",
       "      <td>62.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>src2src</td>\n",
       "      <td>APA_LHA_A2</td>\n",
       "      <td>sentence</td>\n",
       "      <td>3.635</td>\n",
       "      <td>4.092</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.249</td>\n",
       "      <td>45.883</td>\n",
       "      <td>44.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>src2src</td>\n",
       "      <td>APA_LHA_B1</td>\n",
       "      <td>sentence</td>\n",
       "      <td>6.180</td>\n",
       "      <td>5.325</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.286</td>\n",
       "      <td>45.320</td>\n",
       "      <td>44.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>src2src</td>\n",
       "      <td>TCDE19</td>\n",
       "      <td>sentence</td>\n",
       "      <td>27.348</td>\n",
       "      <td>14.999</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.571</td>\n",
       "      <td>27.869</td>\n",
       "      <td>28.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>src2src</td>\n",
       "      <td>Geolingo</td>\n",
       "      <td>sentence</td>\n",
       "      <td>67.116</td>\n",
       "      <td>26.812</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.873</td>\n",
       "      <td>60.829</td>\n",
       "      <td>61.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model     test_set     level    bleu    sari  bertscore_precision  \\\n",
       "0  src2src  DEplain-APA  document  34.247  17.637                0.583   \n",
       "1  src2src  DEplain-web  document  23.132  12.848                0.432   \n",
       "2  src2src        20Min  document   2.051   1.953                0.029   \n",
       "3  src2src  DEplain-APA  sentence  26.893  15.249                0.627   \n",
       "4  src2src  DEplain-web  sentence  20.854  11.931                0.423   \n",
       "5  src2src   APA_LHA_A2  sentence   3.635   4.092                0.184   \n",
       "6  src2src   APA_LHA_B1  sentence   6.180   5.325                0.236   \n",
       "7  src2src       TCDE19  sentence  27.348  14.999                0.546   \n",
       "8  src2src     Geolingo  sentence  67.116  26.812                0.856   \n",
       "\n",
       "   bertscore_recall  bertscore_f1  sent_FRE  corpus_FRE  \n",
       "0             0.605         0.595    61.411       58.85  \n",
       "1             0.569         0.498    56.877       59.40  \n",
       "2             0.359         0.179    54.665       54.45  \n",
       "3             0.642         0.633    59.230       58.75  \n",
       "4             0.489         0.455    60.825       62.95  \n",
       "5             0.320         0.249    45.883       44.90  \n",
       "6             0.340         0.286    45.320       44.90  \n",
       "7             0.597         0.571    27.869       28.10  \n",
       "8             0.891         0.873    60.829       61.50  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify your trial that needs to be evaluated\n",
    "# If you have your outputs already generated and you want to just update the metrics for any reason, set generate_outputs=False\n",
    "evaluate_baseline_src2src(docs_test_sets, sents_test_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3e6765-d8a7-4347-824c-47a438e8c121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60100d5-4463-4b94-8a01-c7fff250a505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eae585d6-8991-4435-8213-c162fe7c5ba7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 4. Evaluate Trained models @ `finetuned_checkpoints`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "693fc4d6-0456-43f5-a657-56908ff291ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scripts import evaluate_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8efde78-7f4d-4bce-bc8f-66b8ac984ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add your test set path to the lists\n",
    "# test set path should point to a directory that contains a `test.src` and `test.tgt` files\n",
    "\n",
    "\n",
    "docs_test_sets = [\n",
    "    'datasets/prepared_datasets/docs/DEplain-APA',\n",
    "    'datasets/prepared_datasets/docs/DEplain-web',\n",
    "    'datasets/prepared_datasets/docs/20Min',\n",
    "]\n",
    "\n",
    "sents_test_sets = [\n",
    "    'datasets/prepared_datasets/sents/DEplain-APA',\n",
    "    'datasets/prepared_datasets/sents/DEplain-web',\n",
    "    'datasets/prepared_datasets/sents/APA_LHA_A2',\n",
    "    'datasets/prepared_datasets/sents/APA_LHA_B1',\n",
    "    'datasets/prepared_datasets/sents/TCDE19',\n",
    "    'datasets/prepared_datasets/sents/Geolingo'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d09f0de-836e-436f-9b60-5ac0eb4ef384",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating document level models\n",
      "==================================================\n",
      "==================================================\n",
      "Evaluating finetuned_checkpoints/trial_1/trimmed_longmbart_35k_DEplain-web/epoch=19_rougeL=0.22304.ckpt\n",
      "--------------------------------------------------\n",
      "====>> Evaluating generated outputs of trimmed_longmbart_35k_DEplain-web on DEplain-APA.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating trimmed_longmbart_35k_DEplain-web on DEplain-APA successfully.\n",
      "Evaluation metrics: {'bleu': 12.913, 'sari': 35.02, 'bertscore_precision': 0.475, 'bertscore_recall': 0.383, 'bertscore_f1': 0.427, 'sent_FRE': 63.166, 'corpus_FRE': 59.55, 'compression_ratio': ' ', 'sentence_splits': ' ', 'levenshtein_similarity': ' ', 'exact_copies': ' ', 'additions_proportion': ' ', 'deletions_proportion': ' ', 'lexical_complexity_score': ' ', 'model': 'trimmed longmbart', 'train_set': 'DEplain-web', 'test_set': 'DEplain-APA', 'rougeL': nan, 'level': 'document'}\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating generated outputs of trimmed_longmbart_35k_DEplain-web on DEplain-web.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating trimmed_longmbart_35k_DEplain-web on DEplain-web successfully.\n",
      "Evaluation metrics: {'bleu': 23.282, 'sari': 49.584, 'bertscore_precision': 0.462, 'bertscore_recall': 0.486, 'bertscore_f1': 0.473, 'sent_FRE': 60.386, 'corpus_FRE': 63.5, 'compression_ratio': ' ', 'sentence_splits': ' ', 'levenshtein_similarity': ' ', 'exact_copies': ' ', 'additions_proportion': ' ', 'deletions_proportion': ' ', 'lexical_complexity_score': ' ', 'model': 'trimmed longmbart', 'train_set': 'DEplain-web', 'test_set': 'DEplain-web', 'rougeL': nan, 'level': 'document'}\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating generated outputs of trimmed_longmbart_35k_DEplain-web on 20Min.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating trimmed_longmbart_35k_DEplain-web on 20Min successfully.\n",
      "Evaluation metrics: {'bleu': 1.81, 'sari': 27.113, 'bertscore_precision': 0.007, 'bertscore_recall': 0.258, 'bertscore_f1': 0.122, 'sent_FRE': 53.397, 'corpus_FRE': 63.5, 'compression_ratio': ' ', 'sentence_splits': ' ', 'levenshtein_similarity': ' ', 'exact_copies': ' ', 'additions_proportion': ' ', 'deletions_proportion': ' ', 'lexical_complexity_score': ' ', 'model': 'trimmed longmbart', 'train_set': 'DEplain-web', 'test_set': '20Min', 'rougeL': nan, 'level': 'document'}\n",
      "==================================================\n",
      "==================================================\n",
      "Evaluating finetuned_checkpoints/trial_1/trimmed_longmbart_35k_DEplain-APA/epoch=15_rougeL=0.49541.ckpt\n",
      "--------------------------------------------------\n",
      "====>> Evaluating generated outputs of trimmed_longmbart_35k_DEplain-APA on DEplain-APA.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating trimmed_longmbart_35k_DEplain-APA on DEplain-APA successfully.\n",
      "Evaluation metrics: {'bleu': 38.136, 'sari': 44.56, 'bertscore_precision': 0.598, 'bertscore_recall': 0.601, 'bertscore_f1': 0.6, 'sent_FRE': 63.795, 'corpus_FRE': 65.4, 'compression_ratio': ' ', 'sentence_splits': ' ', 'levenshtein_similarity': ' ', 'exact_copies': ' ', 'additions_proportion': ' ', 'deletions_proportion': ' ', 'lexical_complexity_score': ' ', 'model': 'trimmed longmbart', 'train_set': 'DEplain-APA', 'test_set': 'DEplain-APA', 'rougeL': nan, 'level': 'document'}\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating generated outputs of trimmed_longmbart_35k_DEplain-APA on DEplain-web.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating trimmed_longmbart_35k_DEplain-APA on DEplain-web successfully.\n",
      "Evaluation metrics: {'bleu': 21.9, 'sari': 43.087, 'bertscore_precision': 0.377, 'bertscore_recall': 0.439, 'bertscore_f1': 0.408, 'sent_FRE': 65.191, 'corpus_FRE': 64.7, 'compression_ratio': ' ', 'sentence_splits': ' ', 'levenshtein_similarity': ' ', 'exact_copies': ' ', 'additions_proportion': ' ', 'deletions_proportion': ' ', 'lexical_complexity_score': ' ', 'model': 'trimmed longmbart', 'train_set': 'DEplain-APA', 'test_set': 'DEplain-web', 'rougeL': nan, 'level': 'document'}\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating generated outputs of trimmed_longmbart_35k_DEplain-APA on 20Min.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating trimmed_longmbart_35k_DEplain-APA on 20Min successfully.\n",
      "Evaluation metrics: {'bleu': 1.706, 'sari': 22.805, 'bertscore_precision': 0.03, 'bertscore_recall': 0.314, 'bertscore_f1': 0.161, 'sent_FRE': 62.446, 'corpus_FRE': 63.9, 'compression_ratio': ' ', 'sentence_splits': ' ', 'levenshtein_similarity': ' ', 'exact_copies': ' ', 'additions_proportion': ' ', 'deletions_proportion': ' ', 'lexical_complexity_score': ' ', 'model': 'trimmed longmbart', 'train_set': 'DEplain-APA', 'test_set': '20Min', 'rougeL': nan, 'level': 'document'}\n",
      "==================================================\n",
      "==================================================\n",
      "Evaluating finetuned_checkpoints/trial_1/trimmed_longmbart_35k_DEplain-APA-web/epoch=17_rougeL=0.29220.ckpt\n",
      "--------------------------------------------------\n",
      "====>> Evaluating generated outputs of trimmed_longmbart_35k_DEplain-APA-web on DEplain-APA.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating trimmed_longmbart_35k_DEplain-APA-web on DEplain-APA successfully.\n",
      "Evaluation metrics: {'bleu': 36.449, 'sari': 42.862, 'bertscore_precision': 0.589, 'bertscore_recall': 0.599, 'bertscore_f1': 0.594, 'sent_FRE': 64.066, 'corpus_FRE': 65.4, 'compression_ratio': ' ', 'sentence_splits': ' ', 'levenshtein_similarity': ' ', 'exact_copies': ' ', 'additions_proportion': ' ', 'deletions_proportion': ' ', 'lexical_complexity_score': ' ', 'model': 'trimmed longmbart', 'train_set': 'DEplain-APA-web', 'test_set': 'DEplain-APA', 'rougeL': nan, 'level': 'document'}\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating generated outputs of trimmed_longmbart_35k_DEplain-APA-web on DEplain-web.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating trimmed_longmbart_35k_DEplain-APA-web on DEplain-web successfully.\n",
      "Evaluation metrics: {'bleu': 23.37, 'sari': 49.745, 'bertscore_precision': 0.445, 'bertscore_recall': 0.46, 'bertscore_f1': 0.451, 'sent_FRE': 55.699, 'corpus_FRE': 57.95, 'compression_ratio': ' ', 'sentence_splits': ' ', 'levenshtein_similarity': ' ', 'exact_copies': ' ', 'additions_proportion': ' ', 'deletions_proportion': ' ', 'lexical_complexity_score': ' ', 'model': 'trimmed longmbart', 'train_set': 'DEplain-APA-web', 'test_set': 'DEplain-web', 'rougeL': nan, 'level': 'document'}\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating generated outputs of trimmed_longmbart_35k_DEplain-APA-web on 20Min.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating trimmed_longmbart_35k_DEplain-APA-web on 20Min successfully.\n",
      "Evaluation metrics: {'bleu': 1.804, 'sari': 24.265, 'bertscore_precision': 0.029, 'bertscore_recall': 0.291, 'bertscore_f1': 0.15, 'sent_FRE': 62.642, 'corpus_FRE': 64.0, 'compression_ratio': ' ', 'sentence_splits': ' ', 'levenshtein_similarity': ' ', 'exact_copies': ' ', 'additions_proportion': ' ', 'deletions_proportion': ' ', 'lexical_complexity_score': ' ', 'model': 'trimmed longmbart', 'train_set': 'DEplain-APA-web', 'test_set': '20Min', 'rougeL': nan, 'level': 'document'}\n",
      "==================================================\n",
      "==================================================\n",
      "==================================================\n",
      "==================================================\n",
      "Evaluating sentence level models\n",
      "==================================================\n",
      "==================================================\n",
      "Evaluating finetuned_checkpoints/trial_1/trimmed_mbart_35k_DEplain-APA-web/epoch=08_rougeL=0.46221.ckpt\n",
      "--------------------------------------------------\n",
      "====>> Evaluating generated outputs of trimmed_mbart_35k_DEplain-APA-web on DEplain-APA.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating finetuned_checkpoints/trial_1/trimmed_mbart_35k_DEplain-APA-web/epoch=08_rougeL=0.46221.ckpt on datasets/prepared_datasets/sents/DEplain-APA successfully.\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating generated outputs of trimmed_mbart_35k_DEplain-APA-web on DEplain-web.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating finetuned_checkpoints/trial_1/trimmed_mbart_35k_DEplain-APA-web/epoch=08_rougeL=0.46221.ckpt on datasets/prepared_datasets/sents/DEplain-web successfully.\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating generated outputs of trimmed_mbart_35k_DEplain-APA-web on APA_LHA_A2.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating finetuned_checkpoints/trial_1/trimmed_mbart_35k_DEplain-APA-web/epoch=08_rougeL=0.46221.ckpt on datasets/prepared_datasets/sents/APA_LHA_A2 successfully.\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating generated outputs of trimmed_mbart_35k_DEplain-APA-web on APA_LHA_B1.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating finetuned_checkpoints/trial_1/trimmed_mbart_35k_DEplain-APA-web/epoch=08_rougeL=0.46221.ckpt on datasets/prepared_datasets/sents/APA_LHA_B1 successfully.\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating generated outputs of trimmed_mbart_35k_DEplain-APA-web on TCDE19.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating finetuned_checkpoints/trial_1/trimmed_mbart_35k_DEplain-APA-web/epoch=08_rougeL=0.46221.ckpt on datasets/prepared_datasets/sents/TCDE19 successfully.\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating generated outputs of trimmed_mbart_35k_DEplain-APA-web on Geolingo.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating finetuned_checkpoints/trial_1/trimmed_mbart_35k_DEplain-APA-web/epoch=08_rougeL=0.46221.ckpt on datasets/prepared_datasets/sents/Geolingo successfully.\n",
      "==================================================\n",
      "==================================================\n",
      "Evaluating finetuned_checkpoints/trial_1/trimmed_mbart_35k_DEplain-APA/epoch=07_rougeL=0.48747.ckpt\n",
      "--------------------------------------------------\n",
      "====>> Evaluating generated outputs of trimmed_mbart_35k_DEplain-APA on DEplain-APA.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating finetuned_checkpoints/trial_1/trimmed_mbart_35k_DEplain-APA/epoch=07_rougeL=0.48747.ckpt on datasets/prepared_datasets/sents/DEplain-APA successfully.\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating generated outputs of trimmed_mbart_35k_DEplain-APA on DEplain-web.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating finetuned_checkpoints/trial_1/trimmed_mbart_35k_DEplain-APA/epoch=07_rougeL=0.48747.ckpt on datasets/prepared_datasets/sents/DEplain-web successfully.\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating generated outputs of trimmed_mbart_35k_DEplain-APA on APA_LHA_A2.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating finetuned_checkpoints/trial_1/trimmed_mbart_35k_DEplain-APA/epoch=07_rougeL=0.48747.ckpt on datasets/prepared_datasets/sents/APA_LHA_A2 successfully.\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating generated outputs of trimmed_mbart_35k_DEplain-APA on APA_LHA_B1.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating finetuned_checkpoints/trial_1/trimmed_mbart_35k_DEplain-APA/epoch=07_rougeL=0.48747.ckpt on datasets/prepared_datasets/sents/APA_LHA_B1 successfully.\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating generated outputs of trimmed_mbart_35k_DEplain-APA on TCDE19.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating finetuned_checkpoints/trial_1/trimmed_mbart_35k_DEplain-APA/epoch=07_rougeL=0.48747.ckpt on datasets/prepared_datasets/sents/TCDE19 successfully.\n",
      "==================================================\n",
      "==================================================\n",
      "====>> Evaluating generated outputs of trimmed_mbart_35k_DEplain-APA on Geolingo.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Finished Evaluating finetuned_checkpoints/trial_1/trimmed_mbart_35k_DEplain-APA/epoch=07_rougeL=0.48747.ckpt on datasets/prepared_datasets/sents/Geolingo successfully.\n",
      "==================================================\n",
      "==================================================\n",
      "==================================================\n",
      "==================================================\n",
      "==================================================\n",
      "==================================================\n",
      "Saving evaluation metrics to csv file...\n",
      "==================================================\n",
      "==================================================\n",
      "==================================================\n",
      "==================================================\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_set</th>\n",
       "      <th>test_set</th>\n",
       "      <th>level</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>bleu</th>\n",
       "      <th>sari</th>\n",
       "      <th>bertscore_precision</th>\n",
       "      <th>bertscore_recall</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>sent_FRE</th>\n",
       "      <th>corpus_FRE</th>\n",
       "      <th>compression_ratio</th>\n",
       "      <th>sentence_splits</th>\n",
       "      <th>levenshtein_similarity</th>\n",
       "      <th>exact_copies</th>\n",
       "      <th>additions_proportion</th>\n",
       "      <th>deletions_proportion</th>\n",
       "      <th>lexical_complexity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trimmed longmbart</td>\n",
       "      <td>DEplain-web</td>\n",
       "      <td>DEplain-APA</td>\n",
       "      <td>document</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.913</td>\n",
       "      <td>35.020</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.427</td>\n",
       "      <td>63.166</td>\n",
       "      <td>59.55</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trimmed longmbart</td>\n",
       "      <td>DEplain-web</td>\n",
       "      <td>DEplain-web</td>\n",
       "      <td>document</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.282</td>\n",
       "      <td>49.584</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.473</td>\n",
       "      <td>60.386</td>\n",
       "      <td>63.50</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trimmed longmbart</td>\n",
       "      <td>DEplain-web</td>\n",
       "      <td>20Min</td>\n",
       "      <td>document</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.810</td>\n",
       "      <td>27.113</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.122</td>\n",
       "      <td>53.397</td>\n",
       "      <td>63.50</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trimmed longmbart</td>\n",
       "      <td>DEplain-APA</td>\n",
       "      <td>DEplain-APA</td>\n",
       "      <td>document</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.136</td>\n",
       "      <td>44.560</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.600</td>\n",
       "      <td>63.795</td>\n",
       "      <td>65.40</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trimmed longmbart</td>\n",
       "      <td>DEplain-APA</td>\n",
       "      <td>DEplain-web</td>\n",
       "      <td>document</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.900</td>\n",
       "      <td>43.087</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.408</td>\n",
       "      <td>65.191</td>\n",
       "      <td>64.70</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trimmed longmbart</td>\n",
       "      <td>DEplain-APA</td>\n",
       "      <td>20Min</td>\n",
       "      <td>document</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.706</td>\n",
       "      <td>22.805</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.161</td>\n",
       "      <td>62.446</td>\n",
       "      <td>63.90</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>trimmed longmbart</td>\n",
       "      <td>DEplain-APA-web</td>\n",
       "      <td>DEplain-APA</td>\n",
       "      <td>document</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.449</td>\n",
       "      <td>42.862</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.594</td>\n",
       "      <td>64.066</td>\n",
       "      <td>65.40</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>trimmed longmbart</td>\n",
       "      <td>DEplain-APA-web</td>\n",
       "      <td>DEplain-web</td>\n",
       "      <td>document</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.370</td>\n",
       "      <td>49.745</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.451</td>\n",
       "      <td>55.699</td>\n",
       "      <td>57.95</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>trimmed longmbart</td>\n",
       "      <td>DEplain-APA-web</td>\n",
       "      <td>20Min</td>\n",
       "      <td>document</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.804</td>\n",
       "      <td>24.265</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.150</td>\n",
       "      <td>62.642</td>\n",
       "      <td>64.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>trimmed mbart</td>\n",
       "      <td>DEplain-APA-web</td>\n",
       "      <td>DEplain-APA</td>\n",
       "      <td>sentence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.506</td>\n",
       "      <td>34.904</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.642</td>\n",
       "      <td>62.669</td>\n",
       "      <td>65.10</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>trimmed mbart</td>\n",
       "      <td>DEplain-APA-web</td>\n",
       "      <td>DEplain-web</td>\n",
       "      <td>sentence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.880</td>\n",
       "      <td>34.828</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.431</td>\n",
       "      <td>65.249</td>\n",
       "      <td>69.35</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>trimmed mbart</td>\n",
       "      <td>DEplain-APA-web</td>\n",
       "      <td>APA_LHA_A2</td>\n",
       "      <td>sentence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.464</td>\n",
       "      <td>28.468</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.282</td>\n",
       "      <td>56.969</td>\n",
       "      <td>57.15</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>trimmed mbart</td>\n",
       "      <td>DEplain-APA-web</td>\n",
       "      <td>APA_LHA_B1</td>\n",
       "      <td>sentence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.604</td>\n",
       "      <td>28.527</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.304</td>\n",
       "      <td>56.848</td>\n",
       "      <td>57.25</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>trimmed mbart</td>\n",
       "      <td>DEplain-APA-web</td>\n",
       "      <td>TCDE19</td>\n",
       "      <td>sentence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.321</td>\n",
       "      <td>36.937</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.497</td>\n",
       "      <td>42.129</td>\n",
       "      <td>43.65</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>trimmed mbart</td>\n",
       "      <td>DEplain-APA-web</td>\n",
       "      <td>Geolingo</td>\n",
       "      <td>sentence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.718</td>\n",
       "      <td>44.913</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.766</td>\n",
       "      <td>66.588</td>\n",
       "      <td>64.80</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>trimmed mbart</td>\n",
       "      <td>DEplain-APA</td>\n",
       "      <td>DEplain-APA</td>\n",
       "      <td>sentence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.250</td>\n",
       "      <td>34.818</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.641</td>\n",
       "      <td>63.072</td>\n",
       "      <td>65.10</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>trimmed mbart</td>\n",
       "      <td>DEplain-APA</td>\n",
       "      <td>DEplain-web</td>\n",
       "      <td>sentence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.727</td>\n",
       "      <td>30.867</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.418</td>\n",
       "      <td>64.516</td>\n",
       "      <td>69.35</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>trimmed mbart</td>\n",
       "      <td>DEplain-APA</td>\n",
       "      <td>APA_LHA_A2</td>\n",
       "      <td>sentence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.294</td>\n",
       "      <td>27.987</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.281</td>\n",
       "      <td>57.865</td>\n",
       "      <td>57.05</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>trimmed mbart</td>\n",
       "      <td>DEplain-APA</td>\n",
       "      <td>APA_LHA_B1</td>\n",
       "      <td>sentence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.495</td>\n",
       "      <td>29.086</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.304</td>\n",
       "      <td>57.299</td>\n",
       "      <td>57.35</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>trimmed mbart</td>\n",
       "      <td>DEplain-APA</td>\n",
       "      <td>TCDE19</td>\n",
       "      <td>sentence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.850</td>\n",
       "      <td>38.964</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.506</td>\n",
       "      <td>44.847</td>\n",
       "      <td>44.85</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trimmed mbart</td>\n",
       "      <td>DEplain-APA</td>\n",
       "      <td>Geolingo</td>\n",
       "      <td>sentence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.802</td>\n",
       "      <td>45.810</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.768</td>\n",
       "      <td>67.282</td>\n",
       "      <td>70.65</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model        train_set     test_set     level  rougeL    bleu  \\\n",
       "0   trimmed longmbart      DEplain-web  DEplain-APA  document     NaN  12.913   \n",
       "1   trimmed longmbart      DEplain-web  DEplain-web  document     NaN  23.282   \n",
       "2   trimmed longmbart      DEplain-web        20Min  document     NaN   1.810   \n",
       "3   trimmed longmbart      DEplain-APA  DEplain-APA  document     NaN  38.136   \n",
       "4   trimmed longmbart      DEplain-APA  DEplain-web  document     NaN  21.900   \n",
       "5   trimmed longmbart      DEplain-APA        20Min  document     NaN   1.706   \n",
       "6   trimmed longmbart  DEplain-APA-web  DEplain-APA  document     NaN  36.449   \n",
       "7   trimmed longmbart  DEplain-APA-web  DEplain-web  document     NaN  23.370   \n",
       "8   trimmed longmbart  DEplain-APA-web        20Min  document     NaN   1.804   \n",
       "9       trimmed mbart  DEplain-APA-web  DEplain-APA  sentence     NaN  28.506   \n",
       "10      trimmed mbart  DEplain-APA-web  DEplain-web  sentence     NaN  17.880   \n",
       "11      trimmed mbart  DEplain-APA-web   APA_LHA_A2  sentence     NaN   5.464   \n",
       "12      trimmed mbart  DEplain-APA-web   APA_LHA_B1  sentence     NaN   6.604   \n",
       "13      trimmed mbart  DEplain-APA-web       TCDE19  sentence     NaN  16.321   \n",
       "14      trimmed mbart  DEplain-APA-web     Geolingo  sentence     NaN  54.718   \n",
       "15      trimmed mbart      DEplain-APA  DEplain-APA  sentence     NaN  28.250   \n",
       "16      trimmed mbart      DEplain-APA  DEplain-web  sentence     NaN  15.727   \n",
       "17      trimmed mbart      DEplain-APA   APA_LHA_A2  sentence     NaN   5.294   \n",
       "18      trimmed mbart      DEplain-APA   APA_LHA_B1  sentence     NaN   6.495   \n",
       "19      trimmed mbart      DEplain-APA       TCDE19  sentence     NaN  16.850   \n",
       "20      trimmed mbart      DEplain-APA     Geolingo  sentence     NaN  56.802   \n",
       "\n",
       "      sari  bertscore_precision  bertscore_recall  bertscore_f1  sent_FRE  \\\n",
       "0   35.020                0.475             0.383         0.427    63.166   \n",
       "1   49.584                0.462             0.486         0.473    60.386   \n",
       "2   27.113                0.007             0.258         0.122    53.397   \n",
       "3   44.560                0.598             0.601         0.600    63.795   \n",
       "4   43.087                0.377             0.439         0.408    65.191   \n",
       "5   22.805                0.030             0.314         0.161    62.446   \n",
       "6   42.862                0.589             0.599         0.594    64.066   \n",
       "7   49.745                0.445             0.460         0.451    55.699   \n",
       "8   24.265                0.029             0.291         0.150    62.642   \n",
       "9   34.904                0.640             0.645         0.642    62.669   \n",
       "10  34.828                0.436             0.430         0.431    65.249   \n",
       "11  28.468                0.236             0.330         0.282    56.969   \n",
       "12  28.527                0.273             0.336         0.304    56.848   \n",
       "13  36.937                0.542             0.458         0.497    42.129   \n",
       "14  44.913                0.778             0.758         0.766    66.588   \n",
       "15  34.818                0.639             0.644         0.641    63.072   \n",
       "16  30.867                0.413             0.425         0.418    64.516   \n",
       "17  27.987                0.232             0.333         0.281    57.865   \n",
       "18  29.086                0.272             0.338         0.304    57.299   \n",
       "19  38.964                0.539             0.476         0.506    44.847   \n",
       "20  45.810                0.769             0.769         0.768    67.282   \n",
       "\n",
       "    corpus_FRE compression_ratio sentence_splits levenshtein_similarity  \\\n",
       "0        59.55                                                            \n",
       "1        63.50                                                            \n",
       "2        63.50                                                            \n",
       "3        65.40                                                            \n",
       "4        64.70                                                            \n",
       "5        63.90                                                            \n",
       "6        65.40                                                            \n",
       "7        57.95                                                            \n",
       "8        64.00                                                            \n",
       "9        65.10                                                            \n",
       "10       69.35                                                            \n",
       "11       57.15                                                            \n",
       "12       57.25                                                            \n",
       "13       43.65                                                            \n",
       "14       64.80                                                            \n",
       "15       65.10                                                            \n",
       "16       69.35                                                            \n",
       "17       57.05                                                            \n",
       "18       57.35                                                            \n",
       "19       44.85                                                            \n",
       "20       70.65                                                            \n",
       "\n",
       "   exact_copies additions_proportion deletions_proportion  \\\n",
       "0                                                           \n",
       "1                                                           \n",
       "2                                                           \n",
       "3                                                           \n",
       "4                                                           \n",
       "5                                                           \n",
       "6                                                           \n",
       "7                                                           \n",
       "8                                                           \n",
       "9                                                           \n",
       "10                                                          \n",
       "11                                                          \n",
       "12                                                          \n",
       "13                                                          \n",
       "14                                                          \n",
       "15                                                          \n",
       "16                                                          \n",
       "17                                                          \n",
       "18                                                          \n",
       "19                                                          \n",
       "20                                                          \n",
       "\n",
       "   lexical_complexity_score  \n",
       "0                            \n",
       "1                            \n",
       "2                            \n",
       "3                            \n",
       "4                            \n",
       "5                            \n",
       "6                            \n",
       "7                            \n",
       "8                            \n",
       "9                            \n",
       "10                           \n",
       "11                           \n",
       "12                           \n",
       "13                           \n",
       "14                           \n",
       "15                           \n",
       "16                           \n",
       "17                           \n",
       "18                           \n",
       "19                           \n",
       "20                           "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify your trial that needs to be evaluated\n",
    "# If you have your outputs already generated and you want to just update the metrics for any reason, set generate_outputs=False\n",
    "evaluate_trial('trial_1', docs_test_sets, sents_test_sets, beam_size=6, generate_outputs=False, anlaysis=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b05985-dc92-4de8-b690-22b6ce1f4568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf70457-aca1-4634-bdf1-52678f11c858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d7c75e-f8e8-4b45-8447-6c5a3eec2529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ad8110-c26a-48df-be7a-6bda678e0ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
